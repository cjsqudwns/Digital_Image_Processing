{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9a44896c-3d93-4635-b0c5-2dc72a990ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03de7ddb-0606-46d5-9d48-f75043fcb92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "def show_img(image, title=\"image\"):\n",
    "    if image is None:\n",
    "        print(\"No data\")\n",
    "    else:\n",
    "        cv2.imshow(title, image)\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()\n",
    "def detail_img(image, read_img):\n",
    "    print(f\"- Data Type: {type(image)}\")\n",
    "    print(f\"- Data Shape: {read_img.shape} + Height x Width x Channel\")\n",
    "    print(f\"- Maximum Intensity: {read_img.max()}\")\n",
    "    print(f\"- Minimum Intensity: {read_img.min()}\")\n",
    "def normalization(image):\n",
    "    image = image.astype(np.float32)\n",
    "    img_norm = ((image - image.min())*(255))/(image.max()-image.min())\n",
    "    img_norm = img_norm.astype(np.uint8)\n",
    "    return img_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304197f-28f0-47dd-99ca-b47e799d6c8e",
   "metadata": {},
   "source": [
    "# 1. function을 이용한 변환\n",
    "## : negative, log, power-law transformation(감마값의 범위에 따라 다양한 결과 분석, >1, <1의 각 범위에서 두가지 값 이상 설정)\n",
    "## : Fig0308, Fig0309, Fig0525"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1017c90d-81b1-4a39-b676-33ba97866daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Data Type: <class 'str'>\n",
      "- Data Shape: (976, 746) + Height x Width x Channel\n",
      "- Maximum Intensity: 255\n",
      "- Minimum Intensity: 0\n",
      "- Data Type: <class 'str'>\n",
      "- Data Shape: (769, 765) + Height x Width x Channel\n",
      "- Maximum Intensity: 255\n",
      "- Minimum Intensity: 0\n",
      "- Data Type: <class 'str'>\n",
      "- Data Shape: (480, 480) + Height x Width x Channel\n",
      "- Maximum Intensity: 211\n",
      "- Minimum Intensity: 44\n",
      "- Data Type: <class 'str'>\n",
      "- Data Shape: (480, 480) + Height x Width x Channel\n",
      "- Maximum Intensity: 231\n",
      "- Minimum Intensity: 33\n"
     ]
    }
   ],
   "source": [
    "# 이미지 주소 설정\n",
    "Fig0308 = \"/Users/cheonbyeongjun/Desktop/Python_File/Digital_Image_Processing/Point_Processing/Homework 1. Point processing example image/HW1-3  Fig0308(a)(fractured_spine) .tif\"\n",
    "Fig0309 = \"/Users/cheonbyeongjun/Desktop/Python_File/Digital_Image_Processing/Point_Processing/Homework 1. Point processing example image/HW1-2 Fig0309(a)(washed_out_aerial_image).tif\"\n",
    "Fig0525_b = \"/Users/cheonbyeongjun/Desktop/Python_File/Digital_Image_Processing/Point_Processing/Homework 1. Point processing example image/HW1-2  Fig0525(b)(aerial_view_turb_c_0pt0025) .tif\"\n",
    "Fig0525_c = \"/Users/cheonbyeongjun/Desktop/Python_File/Digital_Image_Processing/Point_Processing/Homework 1. Point processing example image/HW1-2  Fig0525(c)(aerial_view_turb_c_0pt001).tif\"\n",
    "images = [Fig0308, Fig0309, Fig0525_b, Fig0525_c]\n",
    "read_images = []\n",
    "for image in images:\n",
    "    read_images.append(cv2.imread(image, cv2.IMREAD_UNCHANGED))\n",
    "for i in range(len(images)):\n",
    "    detail_img(images[i], read_images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f472c3f-b820-424b-81db-a7e4b79ef9c4",
   "metadata": {},
   "source": [
    "## 1.1 Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40c5297-88cd-4e48-8714-d8c2e5d3149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative(image):\n",
    "    return (255 - image)\n",
    "negative_images = []\n",
    "for image in read_images:\n",
    "    negative_images.append(negative(image))\n",
    "for img in negative_images:\n",
    "    show_img(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec931ce-81e3-4bc9-98e0-da8436a1c8cb",
   "metadata": {},
   "source": [
    "## 1.2 Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7355a195-3933-48d1-8007-fc0da06f31c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(image):\n",
    "    c = 3\n",
    "    log_image = c * np.log1p(image) * (255 / np.log(256))\n",
    "    img_norm = normalization(log_image)\n",
    "    return img_norm\n",
    "    \n",
    "log_images = []\n",
    "for image in read_images:\n",
    "    log_images.append(log(image))\n",
    "for img in log_images:\n",
    "    show_img(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a8d1f0-c458-4780-962f-1d70a1e6eff9",
   "metadata": {},
   "source": [
    "## 1.3 Power-law transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f668b878-e709-41a8-8395-fcbf30c2b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = 2.0 # 감마값 > 1\n",
    "r2 = 0.5 # 감마값 < 1\n",
    "def power_law_transform(image, r):\n",
    "    power_img = np.power(image, r)\n",
    "    img_norm = normalization(power_img)\n",
    "    return img_norm\n",
    "power_low_r1_images = []\n",
    "power_low_r2_images = []\n",
    "for image in read_images:\n",
    "    power_low_r1_images.append(power_law_transform(image, r1))\n",
    "    power_low_r2_images.append(power_law_transform(image, r2))\n",
    "for img in power_low_r1_images:\n",
    "    show_img(img)\n",
    "for img in power_low_r2_images:\n",
    "    show_img(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449fd0cd-e4a6-486b-b4bf-b72e90cf8622",
   "metadata": {},
   "source": [
    "  # 2. Histogram Processing을 통한 대비 개선\n",
    "  ## : Histogram Equalization 구현\n",
    "  ## : Fig0316"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e42b226-9a68-407e-98db-7320fc248d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Data Type: <class 'str'>\n",
      "- Data Shape: (500, 500) + Height x Width x Channel\n",
      "- Maximum Intensity: 255\n",
      "- Minimum Intensity: 132\n",
      "- Data Type: <class 'str'>\n",
      "- Data Shape: (500, 500) + Height x Width x Channel\n",
      "- Maximum Intensity: 138\n",
      "- Minimum Intensity: 91\n",
      "- Data Type: <class 'str'>\n",
      "- Data Shape: (500, 500) + Height x Width x Channel\n",
      "- Maximum Intensity: 255\n",
      "- Minimum Intensity: 0\n",
      "- Data Type: <class 'str'>\n",
      "- Data Shape: (500, 500) + Height x Width x Channel\n",
      "- Maximum Intensity: 83\n",
      "- Minimum Intensity: 13\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "Fig0316_1 = \"/Users/cheonbyeongjun/Desktop/Python_File/Digital_Image_Processing/Point_Processing/Homework 1. Point processing example image/HW1-1 Fig0316(1)(top_left).jpg\"\n",
    "Fig0316_2 = \"/Users/cheonbyeongjun/Desktop/Python_File/Digital_Image_Processing/Point_Processing/Homework 1. Point processing example image/HW1-1 Fig0316(2)(2nd_from_top).jpg\"\n",
    "Fig0316_3 = \"/Users/cheonbyeongjun/Desktop/Python_File/Digital_Image_Processing/Point_Processing/Homework 1. Point processing example image/HW1-1 Fig0316(3)(third_from_top).jpg\"\n",
    "Fig0316_4 = \"/Users/cheonbyeongjun/Desktop/Python_File/Digital_Image_Processing/Point_Processing/Homework 1. Point processing example image/HW1-1 Fig0316(4)(bottom_left).jpg\"\n",
    "\n",
    "images = [Fig0316_1, Fig0316_2, Fig0316_3, Fig0316_4]\n",
    "read_images = []\n",
    "for image in images:\n",
    "    read_images.append(cv2.imread(image, cv2.IMREAD_UNCHANGED))\n",
    "for i in range(len(images)):\n",
    "    detail_img(images[i], read_images[i])\n",
    "print(read_images[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "911c598f-9c37-407b-82d1-54c904c87466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalization(image):\n",
    "    # histogram 0으로 초기화\n",
    "    histogram = np.zeros(256, dtype=int)\n",
    "    # histogram 계산\n",
    "    for i in image:\n",
    "        for j in i:\n",
    "            histogram[j] +=1\n",
    "    # 누적 합 histogram 초기화\n",
    "    sum_hist = np.zeros(256, dtype=int)\n",
    "    sum = 0\n",
    "    # 누적 합 histogram 계산\n",
    "    for i in range(256):\n",
    "        sum += histogram[i]\n",
    "        sum_hist[i] = sum\n",
    "    # normalized sum histogram 초기화\n",
    "    normalized_sum_hist = np.zeros(256, dtype=int)\n",
    "    # normalized sum histogram 계산\n",
    "    for i in range(256):\n",
    "        normalized_sum = sum_hist[i] * (255.0 / (image.shape[0] * image.shape[1]))\n",
    "        normalized_sum_hist[i] = np.round(normalized_sum, 0)\n",
    "    # 여기까지 look-up table 완성\n",
    "    transformed_image = np.zeros((image.shape[0], image.shape[1]), dtype=int)\n",
    "    # 완성한 look-up table을 이용해 image transform\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            transformed_image[i][j] = normalized_sum_hist[image[i][j]]\n",
    "    return np.array(transformed_image, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae92b94e-e76e-4ab8-b18e-f439c82445ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in read_images:\n",
    "    show_img(histogram_equalization(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d080ef-5331-4fb3-a3cd-e88f862f1758",
   "metadata": {},
   "source": [
    "# 3. 컬러영상에서의 point processing\n",
    "## : HSI 변환 후, Intensity에 대해 위의 point processing을 수행한 후, 결과 영상을 RGB로 변환해서 출력\n",
    "## : HSI 변환은 라이브러리로 처리 가능\n",
    "## : 첨부된 컬러 영상들(baboon, Lenna, peppers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6df957a2-7479-4b57-bc3c-5d32cf5598a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Data Type: <class 'str'>\n",
      "- Data Shape: (512, 512, 3) + Height x Width x Channel\n",
      "- Maximum Intensity: 255\n",
      "- Minimum Intensity: 0\n",
      "- Data Type: <class 'str'>\n",
      "- Data Shape: (440, 440, 3) + Height x Width x Channel\n",
      "- Maximum Intensity: 255\n",
      "- Minimum Intensity: 0\n",
      "- Data Type: <class 'str'>\n",
      "- Data Shape: (512, 512, 3) + Height x Width x Channel\n",
      "- Maximum Intensity: 237\n",
      "- Minimum Intensity: 0\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "baboon = \"/Users/cheonbyeongjun/Desktop/Python_File/Digital_Image_Processing/Point_Processing/Homework 1. Point processing example image/baboon.png\"\n",
    "lenna = \"/Users/cheonbyeongjun/Desktop/Python_File/Digital_Image_Processing/Point_Processing/Homework 1. Point processing example image/Lenna_(test_image).Webp\"\n",
    "pepper = \"/Users/cheonbyeongjun/Desktop/Python_File/Digital_Image_Processing/Point_Processing/Homework 1. Point processing example image/peppers.png\"\n",
    "images = [baboon, lenna, pepper]\n",
    "\n",
    "read_images = []\n",
    "# 컬러로 이미지 읽기\n",
    "for image in images:\n",
    "    read_images.append(cv2.imread(image, cv2.IMREAD_COLOR))\n",
    "for i in range(len(images)):\n",
    "    detail_img(images[i], read_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa001728-027e-4e39-b4b2-e6a7a66cbc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB -> HSV(HSI)\n",
    "def convert_RGB2HSI(image):\n",
    "    return cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "# HSV(HSI)에서 H, S, V 분리\n",
    "def split_HSI(HSI_image):\n",
    "    h, s, i = cv2.split(HSI_image)\n",
    "    return h, s, i\n",
    "# HSV(HSI) -> RGB\n",
    "def convert_HSI2RGB(image):\n",
    "    return cv2.cvtColor(image,cv2.COLOR_HSV2RGB)\n",
    "# HSI image -> negative \n",
    "def negative_HSI(HSI_image):\n",
    "    h, s, i = split_HSI(HSI_image)\n",
    "    negative_i = negative(i)\n",
    "    return cv2.merge([h, s, negative_i])\n",
    "# HSI image -> log\n",
    "def log_HSI(HSI_image):\n",
    "    h, s, i = split_HSI(HSI_image)\n",
    "    log_i = log(i)\n",
    "    return cv2.merge([h, s, log_i])\n",
    "# HSI image -> power-law\n",
    "def power_law_HSI(HSI_image, r):\n",
    "    h, s, i = split_HSI(HSI_image)\n",
    "    power_law_i = power_law_transform(i, r)\n",
    "    return cv2.merge([h, s, power_law_i])\n",
    "def histogram_equalization_HSI(HSI_image):\n",
    "    h, s, i = split_HSI(HSI_image)\n",
    "    histogram_equalization_i = histogram_equalization(i)\n",
    "    return cv2.merge([h, s, histogram_equalization_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1da9fe54-03bb-42ee-891d-de236378001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB image -> HSI image로 변환\n",
    "HSI_images = []\n",
    "for image in read_images:\n",
    "    HSI_images.append(convert_RGB2HSI(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "166f18ea-3408-4fd2-9904-ad104857e477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative\n",
    "for image in HSI_images:\n",
    "    negative_img = negative_HSI(image)\n",
    "    back2RGB_img = convert_HSI2RGB(negative_img)\n",
    "    show_img(back2RGB_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c4754b3-ca12-4628-8f69-3f0536e99bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log\n",
    "for image in HSI_images:\n",
    "    log_img = log_HSI(image)\n",
    "    back2RGB_img = convert_HSI2RGB(log_img)\n",
    "    show_img(back2RGB_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e6609-dc4a-4524-9d1e-9b6d3aaeb54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# power-law\n",
    "r1 = 2.0 # 감마값 > 1\n",
    "r2 = 0.5 # 감마값 < 1\n",
    "for image in HSI_images:\n",
    "    power_law_img = power_law_HSI(image, r1)\n",
    "    back2RGB_img = convert_HSI2RGB(power_law_img)\n",
    "    show_img(back2RGB_img)\n",
    "    power_law_img = power_law_HSI(image, r2)\n",
    "    back2RGB_img = convert_HSI2RGB(power_law_img)\n",
    "    show_img(back2RGB_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "b9d16ce3-d8a4-43ad-8700-6d5eec0f9444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram equalization\n",
    "for image in HSI_images:\n",
    "    histogram_equalization_img = histogram_equalization_HSI(image)\n",
    "    back2RGB_img = convert_HSI2RGB(histogram_equalization_img)\n",
    "    show_img(back2RGB_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
